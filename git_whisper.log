commit 9a288d5827aa11a03daa6f4b18c53bae1742ee98
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 15:26:18 2026 -0500

    Fix hailo-whisper installation bug in setup.sh

diff --git a/setup.sh b/setup.sh
index 52da6ee..d810a37 100755
--- a/setup.sh
+++ b/setup.sh
@@ -80,14 +80,12 @@ pip install -r requirements.txt
 if [ ! -d "hailo_whisper" ]; then
     echo -e "${YELLOW}Extracting hailo-whisper natively to bypass setuptools...${NC}"
     git clone https://github.com/hailocs/hailo-whisper.git tmp_whisper
-    mv tmp_whisper/hailo_whisper .
+    # The whole repo acts as the package, so we just rename the cloned root folder
+    mv tmp_whisper hailo_whisper
     
     # Change == to >= in its requirements so pip can find valid pre-compiled wheels
-    sed -i 's/==/>=/g' tmp_whisper/requirements.txt
-    pip install -r tmp_whisper/requirements.txt
-    
-    # Cleanup
-    rm -rf tmp_whisper
+    sed -i 's/==/>=/g' hailo_whisper/requirements.txt
+    pip install -r hailo_whisper/requirements.txt
 fi
 
 # 7. Pull AI Models

commit aab8a5450dc81fe96722cd4a44a4fe2c55b76a5e
Author: Will Moore <will@clevercode.ca>
Date:   Thu Feb 26 16:59:48 2026 -0500

    fix pip errors

diff --git a/setup.sh b/setup.sh
index cc33a64..a2d00e3 100755
--- a/setup.sh
+++ b/setup.sh
@@ -76,14 +76,19 @@ source venv/bin/activate
 pip install --upgrade pip setuptools wheel
 pip install -r requirements.txt
 
-# Manually install hailo-whisper to bypass strict scipy/torch versions that break on Pi
-if [ ! -d "hailo-whisper" ]; then
-    echo -e "${YELLOW}Cloning hailo-whisper to relax strict dependencies...${NC}"
-    git clone https://github.com/hailocs/hailo-whisper.git
+# Manually extract hailo_whisper to bypass setuptools packaging errors on Pi
+if [ ! -d "hailo_whisper" ]; then
+    echo -e "${YELLOW}Extracting hailo-whisper natively to bypass setuptools...${NC}"
+    git clone https://github.com/hailocs/hailo-whisper.git tmp_whisper
+    mv tmp_whisper/hailo_whisper .
+    
+    # Change == to >= in its requirements so pip can find valid pre-compiled wheels
+    sed -i 's/==/>=/g' tmp_whisper/requirements.txt
+    pip install -r tmp_whisper/requirements.txt
+    
+    # Cleanup
+    rm -rf tmp_whisper
 fi
-# Change == to >= in its requirements so pip can find valid pre-compiled wheels for Python 3.13
-sed -i 's/==/>=/g' hailo-whisper/requirements.txt
-pip install ./hailo-whisper
 
 # 7. Pull AI Models
 echo -e "${YELLOW}[7/7] Checking AI Models...${NC}"

commit 97ed41ba805d271dcdba5cdeb51ead230195a1e2
Author: Will Moore <will@clevercode.ca>
Date:   Thu Feb 26 11:07:43 2026 -0800

    Integrate Hailo Whisper STT and config updates
    
    Switch STT pipeline to hailo-whisper (Hailo-10H NPU): add a hailo_whisper-based transcribe flow with librosa/soundfile preprocessing, a persistent inferencer loader, error handling and temp WAV cleanup. Update configs to point to models/whisper-small.hef and standardize LLM/Vision model names to llama3.2:1b / qwen2-vl-instruct:2b where applicable. Update README with Hailo Whisper usage, model download instructions, and models/ folder note. Modify setup.sh to create models/ and warn users to manually place the .hef file. Logging and user-facing warnings added when hailo-whisper or the HEF model are missing.

diff --git a/core/stt.py b/core/stt.py
index 5b7027d..21ff916 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -1,56 +1,90 @@
-import subprocess
 import logging
 import os
 import re
-from .config import WHISPER_CMD, WHISPER_MODEL
+import soundfile as sf
+import librosa
+import numpy as np
+from .config import WHISPER_MODEL
+
+try:
+    from hailo_whisper import HailoWhisper
+except ImportError:
+    HailoWhisper = None
+    print("WARNING: hailo-whisper is not installed. STT will fail.")
 
 logger = logging.getLogger(__name__)
 
+# Global inferencer to avoid reloading the HEF model for every sentence
+_inferencer = None
+
+def get_inferencer():
+    global _inferencer
+    if _inferencer is None:
+        if HailoWhisper is None:
+            logger.error("hailo-whisper library is missing!")
+            return None
+        
+        if not os.path.exists(WHISPER_MODEL):
+            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
+            logger.error("Please download whisper-small.hef (or base) and place it in the models directory.")
+            return None
+            
+        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
+        try:
+            _inferencer = HailoWhisper(WHISPER_MODEL)
+            logger.info("Hailo Whisper model loaded successfully on the NPU.")
+        except Exception as e:
+            logger.error(f"Failed to load Hailo Whisper model: {e}")
+            return None
+            
+    return _inferencer
+
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
+    Transcribes the audio file using the Hailo-10H NPU via hailo-whisper.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    temp_wav = f"{audio_filepath}_16k.wav"
+    inferencer = get_inferencer()
+    if inferencer is None:
+        return ""
 
     try:
-        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
-        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
-        subprocess.run(
-            ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
-            check=True,
-            stdout=subprocess.DEVNULL,
-            stderr=subprocess.DEVNULL
-        )
-
-        # 2. Run whisper.cpp
-        logger.info("Running whisper.cpp transcription...")
-        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
-
-        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
-
-        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        logger.info(f"Loading and resampling {audio_filepath} to 16kHz for NPU inference...")
+        # Load and convert to 16kHz mono explicitly using librosa
+        audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
+        
+        # Write back to a clean 16k wav temp file since HailoWhisper transcribe() takes a file path
+        temp_wav = f"{audio_filepath}_16k.wav"
+        sf.write(temp_wav, audio_data, 16000)
+        
+        logger.info("Transcribing audio on the Hailo NPU...")
+        result = inferencer.transcribe(temp_wav)
+        
+        # Clean up temp file
+        if os.path.exists(temp_wav):
+            try:
+                os.remove(temp_wav)
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
+            
+        # Parse the result
+        if isinstance(result, dict) and 'text' in result:
+            output = result['text'].strip()
+        else:
+            output = str(result).strip()
+
+        # Clean up tags or timestamp brackets that may leak
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix common misspellings of BMO
+        # Fix capitalization of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
-    except subprocess.CalledProcessError as e:
-        logger.error(f"FFmpeg or Whisper process failed: {e}")
-        return ""
     except Exception as e:
-        logger.error(f"Transcription Error: {e}")
+        logger.error(f"Hailo Transcription Error: {e}")
         return ""
-    finally:
-        # Clean up the temporary 16k wav file
-        if os.path.exists(temp_wav):
-            try:
-                os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
