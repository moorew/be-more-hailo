commit b47cce1861c40c71b57eecff84566e343223d22a
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 23:55:17 2026 -0500

    Rewrite core/stt.py to use native GenAI with properly normalized float32 numpy buffers

diff --git a/core/stt.py b/core/stt.py
index f1c91e1..490bcbe 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -1,90 +1,111 @@
 import logging
 import os
+import sys
 import re
-import soundfile as sf
 import librosa
 import numpy as np
+
+# Make sure hailo_platform genai can be found
+sys.path.append("/usr/lib/python3/dist-packages")
+
 from .config import WHISPER_MODEL
 
 try:
-    from hailo_whisper import HailoWhisper
-except ImportError:
-    HailoWhisper = None
-    print("WARNING: hailo-whisper is not installed. STT will fail.")
+    from hailo_platform import VDevice
+    from hailo_platform.genai import Speech2Text, Speech2TextTask
+    _HAILO_AVAILABLE = True
+except ImportError as e:
+    _HAILO_AVAILABLE = False
+    print(f"WARNING: hailo_platform is not installed or accessible. STT will fail. {e}")
 
 logger = logging.getLogger(__name__)
 
-# Global inferencer to avoid reloading the HEF model for every sentence
-_inferencer = None
+# Multiplexed NPU group
+_SHARED_VDEVICE_GROUP_ID = "SHARED"
+
+_vdevice = None
+_speech2text = None
 
 def get_inferencer():
-    global _inferencer
-    if _inferencer is None:
-        if HailoWhisper is None:
-            logger.error("hailo-whisper library is missing!")
-            return None
-        
+    global _vdevice, _speech2text
+    
+    if not _HAILO_AVAILABLE:
+        logger.error("hailo_platform library is missing! Cannot run STT.")
+        return None
+
+    if _speech2text is None:
         if not os.path.exists(WHISPER_MODEL):
             logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
-            logger.error("Please ensure Whisper-Base.hef is in the models directory.")
             return None
             
-        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
+        logger.info("Initializing Hailo VDevice for STT...")
         try:
-            _inferencer = HailoWhisper(WHISPER_MODEL)
-            logger.info("Hailo Whisper model loaded successfully on the NPU.")
+            params = VDevice.create_params()
+            params.group_id = _SHARED_VDEVICE_GROUP_ID
+            _vdevice = VDevice(params)
+            
+            abs_model_path = os.path.abspath(WHISPER_MODEL)
+            logger.info(f"Loading Hailo Whisper model from {abs_model_path}...")
+            _speech2text = Speech2Text(_vdevice, abs_model_path)
+            logger.info("Native Hailo Whisper model loaded successfully on the NPU.")
         except Exception as e:
-            logger.error(f"Failed to load Hailo Whisper model: {e}")
+            logger.error(f"Failed to load Native Hailo Whisper model: {e}", exc_info=True)
             return None
             
-    return _inferencer
+    return _speech2text
 
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Transcribes the audio file using the Hailo-10H NPU via hailo-whisper.
+    Transcribes the audio file using the Hailo-10H NPU via Native GenAI API.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    inferencer = get_inferencer()
-    if inferencer is None:
+    speech2text = get_inferencer()
+    if speech2text is None:
         return ""
 
     try:
-        logger.info(f"Loading and resampling {audio_filepath} to 16kHz for NPU inference...")
-        # Load and convert to 16kHz mono explicitly using librosa
+        logger.info(f"Loading {audio_filepath} and resampling to 16kHz mono for NPU inference...")
+        
+        # Load audio using librosa (forces 16kHz mono explicitly)
         audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
         
-        # Write back to a clean 16k wav temp file since HailoWhisper transcribe() takes a file path
-        temp_wav = f"{audio_filepath}_16k.wav"
-        sf.write(temp_wav, audio_data, 16000)
+        # Convert to float32 as expected by C++ GenAI wrapper and ensure little-endian
+        audio_data = audio_data.astype(np.float32)
+        audio_data = audio_data.astype('<f4')
         
-        logger.info("Transcribing audio on the Hailo NPU...")
-        result = inferencer.transcribe(temp_wav)
+        logger.info("Transcribing audio with Native Whisper NPU...")
+        segments = speech2text.generate_all_segments(
+            audio_data=audio_data,
+            task=Speech2TextTask.TRANSCRIBE,
+            language="en",
+            timeout_ms=15000
+        )
         
-        # Clean up temp file
-        if os.path.exists(temp_wav):
-            try:
-                os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
+        if segments and len(segments) > 0:
+            transcription = ''.join([seg.text for seg in segments])
+            logger.info(f"Transcription completed: {transcription.strip()}")
+            output = transcription.strip()
             
-        # Parse the result
-        if isinstance(result, dict) and 'text' in result:
-            output = result['text'].strip()
-        else:
-            output = str(result).strip()
-
-        # Clean up tags or timestamp brackets that may leak
-        output = re.sub(r'\[.*?\]', '', output).strip()
-
-        # Fix capitalization of BMO
-        output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
-        output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
-
-        return output
+            # Clean up tags or timestamp brackets that may leak
+            output = re.sub(r'\[.*?\]', '', output).strip()
 
+            # Fix capitalization of BMO
+            output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
+            output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
+            
+            # Clean hallucinated whispers from silence
+            lowered = output.lower()
+            if lowered in ["[silence]", "(silence)", "you", "thanks for watching!", "[blank_audio]"]:
+                return ""
+            
+            return output
+        else:
+            logger.warning("No transcription generated by Hailo NPU.")
+            return ""
+            
     except Exception as e:
-        logger.error(f"Hailo Transcription Error: {e}")
+        logger.error(f"Hailo Transcription Error: {e}", exc_info=True)
         return ""

commit 2f66bed4d94f92773e92ffa7c4170643562db419
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 21:24:22 2026 -0500

    Restore actual working hailo_whisper wrapper integration

diff --git a/core/stt.py b/core/stt.py
index 5b7027d..f1c91e1 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -1,56 +1,90 @@
-import subprocess
 import logging
 import os
 import re
-from .config import WHISPER_CMD, WHISPER_MODEL
+import soundfile as sf
+import librosa
+import numpy as np
+from .config import WHISPER_MODEL
+
+try:
+    from hailo_whisper import HailoWhisper
+except ImportError:
+    HailoWhisper = None
+    print("WARNING: hailo-whisper is not installed. STT will fail.")
 
 logger = logging.getLogger(__name__)
 
+# Global inferencer to avoid reloading the HEF model for every sentence
+_inferencer = None
+
+def get_inferencer():
+    global _inferencer
+    if _inferencer is None:
+        if HailoWhisper is None:
+            logger.error("hailo-whisper library is missing!")
+            return None
+        
+        if not os.path.exists(WHISPER_MODEL):
+            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
+            logger.error("Please ensure Whisper-Base.hef is in the models directory.")
+            return None
+            
+        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
+        try:
+            _inferencer = HailoWhisper(WHISPER_MODEL)
+            logger.info("Hailo Whisper model loaded successfully on the NPU.")
+        except Exception as e:
+            logger.error(f"Failed to load Hailo Whisper model: {e}")
+            return None
+            
+    return _inferencer
+
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
+    Transcribes the audio file using the Hailo-10H NPU via hailo-whisper.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    temp_wav = f"{audio_filepath}_16k.wav"
+    inferencer = get_inferencer()
+    if inferencer is None:
+        return ""
 
     try:
-        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
-        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
-        subprocess.run(
-            ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
-            check=True,
-            stdout=subprocess.DEVNULL,
-            stderr=subprocess.DEVNULL
-        )
-
-        # 2. Run whisper.cpp
-        logger.info("Running whisper.cpp transcription...")
-        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
-
-        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
-
-        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        logger.info(f"Loading and resampling {audio_filepath} to 16kHz for NPU inference...")
+        # Load and convert to 16kHz mono explicitly using librosa
+        audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
+        
+        # Write back to a clean 16k wav temp file since HailoWhisper transcribe() takes a file path
+        temp_wav = f"{audio_filepath}_16k.wav"
+        sf.write(temp_wav, audio_data, 16000)
+        
+        logger.info("Transcribing audio on the Hailo NPU...")
+        result = inferencer.transcribe(temp_wav)
+        
+        # Clean up temp file
+        if os.path.exists(temp_wav):
+            try:
+                os.remove(temp_wav)
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
+            
+        # Parse the result
+        if isinstance(result, dict) and 'text' in result:
+            output = result['text'].strip()
+        else:
+            output = str(result).strip()
+
+        # Clean up tags or timestamp brackets that may leak
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix common misspellings of BMO
+        # Fix capitalization of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
-    except subprocess.CalledProcessError as e:
-        logger.error(f"FFmpeg or Whisper process failed: {e}")
-        return ""
     except Exception as e:
-        logger.error(f"Transcription Error: {e}")
+        logger.error(f"Hailo Transcription Error: {e}")
         return ""
-    finally:
-        # Clean up the temporary 16k wav file
-        if os.path.exists(temp_wav):
-            try:
-                os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")

commit 26e71170929a63ceaf579bc3f7db7ebee2d01692
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 21:24:05 2026 -0500

    Restore user hailo_whisper logic

diff --git a/core/stt.py b/core/stt.py
index 5c3eada..5b7027d 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -2,77 +2,23 @@ import subprocess
 import logging
 import os
 import re
-import wave
-import numpy as np
-import sys
-from .config import WHISPER_MODEL
-
-# Ensure system packages are available inside the venv so we can access the native Hailo SDK
-sys.path.append("/usr/lib/python3/dist-packages")
-
-try:
-    from hailo_platform import VDevice
-    from hailo_platform.genai import Speech2Text, Speech2TextTask
-except ImportError:
-    VDevice, Speech2Text, Speech2TextTask = None, None, None
-    print("WARNING: hailo_platform is not installed. NPU STT will fail.")
+from .config import WHISPER_CMD, WHISPER_MODEL
 
 logger = logging.getLogger(__name__)
 
-# Global inferencer to avoid reloading the HEF model for every sentence
-_vdevice = None
-_speech2text = None
-_SHARED_VDEVICE_GROUP_ID = "SHARED"
-
-def get_inferencer():
-    global _vdevice, _speech2text
-    if _speech2text is None:
-        if Speech2Text is None:
-            logger.error("hailo_platform library is missing! Cannot initialize NPU STT.")
-            return None
-        
-        if not os.path.exists(WHISPER_MODEL):
-            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
-            return None
-            
-        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
-        try:
-            params = VDevice.create_params()
-            params.group_id = _SHARED_VDEVICE_GROUP_ID
-            _vdevice = VDevice(params)
-            
-            abs_model_path = os.path.abspath(WHISPER_MODEL)
-            logger.info(f"Resolved HEF absolute path: {abs_model_path}")
-            _speech2text = Speech2Text(_vdevice, abs_model_path)
-            logger.info("Hailo Whisper model loaded successfully on the NPU.")
-        except Exception as e:
-            logger.error(f"Failed to load Hailo Whisper model: {e}")
-            if _vdevice:
-                try:
-                    _vdevice.release()
-                except Exception:
-                    pass
-                _vdevice = None
-            return None
-            
-    return _speech2text
-
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Transcribes the audio file using the Hailo-10H NPU via hailo_platform.genai.
+    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    inferencer = get_inferencer()
-    if inferencer is None:
-        return ""
-
     temp_wav = f"{audio_filepath}_16k.wav"
 
     try:
-        # Convert audio to 16kHz mono WAV 
+        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
+        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
         subprocess.run(
             ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
             check=True,
@@ -80,45 +26,31 @@ def transcribe_audio(audio_filepath: str) -> str:
             stderr=subprocess.DEVNULL
         )
 
-        with wave.open(temp_wav, 'rb') as wav_file:
-            frames = wav_file.getnframes()
-            raw_audio = wav_file.readframes(frames)
-            
-        # Convert to numpy array based on 16-bit PCM
-        audio_data = np.frombuffer(raw_audio, dtype=np.int16)
-        # Convert 16-bit to float32 and normalize
-        audio_data = audio_data.astype(np.float32) / 32768.0
-        # Ensure little-endian format as expected by the model
-        audio_data = audio_data.astype('<f4')
-
-        # Generate segments
-        segments = inferencer.generate_all_segments(
-            audio_data=audio_data,
-            task=Speech2TextTask.TRANSCRIBE,
-            language="en",
-            timeout_ms=15000
-        )
+        # 2. Run whisper.cpp
+        logger.info("Running whisper.cpp transcription...")
+        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
 
-        if not segments:
-            return ""
+        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
 
-        output = ''.join([seg.text for seg in segments]).strip()
-
-        # Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix capitalization of BMO
+        # Fix common misspellings of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
+    except subprocess.CalledProcessError as e:
+        logger.error(f"FFmpeg or Whisper process failed: {e}")
+        return ""
     except Exception as e:
-        logger.error(f"Hailo Transcription Error: {e}")
+        logger.error(f"Transcription Error: {e}")
         return ""
     finally:
+        # Clean up the temporary 16k wav file
         if os.path.exists(temp_wav):
             try:
                 os.remove(temp_wav)
-            except Exception:
-                pass
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")

commit 16592e3d0410684dbd45a85e21b94239f5b80b0d
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 21:18:47 2026 -0500

    Cast WHISPER_MODEL to absolute path to prevent C++ genai crash

diff --git a/core/stt.py b/core/stt.py
index 2be1a90..5c3eada 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -41,7 +41,9 @@ def get_inferencer():
             params.group_id = _SHARED_VDEVICE_GROUP_ID
             _vdevice = VDevice(params)
             
-            _speech2text = Speech2Text(_vdevice, WHISPER_MODEL)
+            abs_model_path = os.path.abspath(WHISPER_MODEL)
+            logger.info(f"Resolved HEF absolute path: {abs_model_path}")
+            _speech2text = Speech2Text(_vdevice, abs_model_path)
             logger.info("Hailo Whisper model loaded successfully on the NPU.")
         except Exception as e:
             logger.error(f"Failed to load Hailo Whisper model: {e}")

commit bfd810c1eb5da2c5181271556b8ac4d80dfd3afe
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 18:41:41 2026 -0500

    Fix HAILO_COMMUNICATION_CLOSED by using the correct SHARED vdevice group id

diff --git a/core/stt.py b/core/stt.py
index db4b4ec..2be1a90 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -22,7 +22,7 @@ logger = logging.getLogger(__name__)
 # Global inferencer to avoid reloading the HEF model for every sentence
 _vdevice = None
 _speech2text = None
-_SHARED_VDEVICE_GROUP_ID = "hailo_shared_vdevice"
+_SHARED_VDEVICE_GROUP_ID = "SHARED"
 
 def get_inferencer():
     global _vdevice, _speech2text

commit d9c8531e1b958038a9cf34c128c9eb8126c48c86
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 17:52:06 2026 -0500

    Implement native Hailo-10H NPU STT using hailo_platform.genai

diff --git a/core/stt.py b/core/stt.py
index 5b7027d..db4b4ec 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -2,23 +2,75 @@ import subprocess
 import logging
 import os
 import re
-from .config import WHISPER_CMD, WHISPER_MODEL
+import wave
+import numpy as np
+import sys
+from .config import WHISPER_MODEL
+
+# Ensure system packages are available inside the venv so we can access the native Hailo SDK
+sys.path.append("/usr/lib/python3/dist-packages")
+
+try:
+    from hailo_platform import VDevice
+    from hailo_platform.genai import Speech2Text, Speech2TextTask
+except ImportError:
+    VDevice, Speech2Text, Speech2TextTask = None, None, None
+    print("WARNING: hailo_platform is not installed. NPU STT will fail.")
 
 logger = logging.getLogger(__name__)
 
+# Global inferencer to avoid reloading the HEF model for every sentence
+_vdevice = None
+_speech2text = None
+_SHARED_VDEVICE_GROUP_ID = "hailo_shared_vdevice"
+
+def get_inferencer():
+    global _vdevice, _speech2text
+    if _speech2text is None:
+        if Speech2Text is None:
+            logger.error("hailo_platform library is missing! Cannot initialize NPU STT.")
+            return None
+        
+        if not os.path.exists(WHISPER_MODEL):
+            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
+            return None
+            
+        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
+        try:
+            params = VDevice.create_params()
+            params.group_id = _SHARED_VDEVICE_GROUP_ID
+            _vdevice = VDevice(params)
+            
+            _speech2text = Speech2Text(_vdevice, WHISPER_MODEL)
+            logger.info("Hailo Whisper model loaded successfully on the NPU.")
+        except Exception as e:
+            logger.error(f"Failed to load Hailo Whisper model: {e}")
+            if _vdevice:
+                try:
+                    _vdevice.release()
+                except Exception:
+                    pass
+                _vdevice = None
+            return None
+            
+    return _speech2text
+
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
+    Transcribes the audio file using the Hailo-10H NPU via hailo_platform.genai.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
+    inferencer = get_inferencer()
+    if inferencer is None:
+        return ""
+
     temp_wav = f"{audio_filepath}_16k.wav"
 
     try:
-        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
-        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
+        # Convert audio to 16kHz mono WAV 
         subprocess.run(
             ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
             check=True,
@@ -26,31 +78,45 @@ def transcribe_audio(audio_filepath: str) -> str:
             stderr=subprocess.DEVNULL
         )
 
-        # 2. Run whisper.cpp
-        logger.info("Running whisper.cpp transcription...")
-        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
+        with wave.open(temp_wav, 'rb') as wav_file:
+            frames = wav_file.getnframes()
+            raw_audio = wav_file.readframes(frames)
+            
+        # Convert to numpy array based on 16-bit PCM
+        audio_data = np.frombuffer(raw_audio, dtype=np.int16)
+        # Convert 16-bit to float32 and normalize
+        audio_data = audio_data.astype(np.float32) / 32768.0
+        # Ensure little-endian format as expected by the model
+        audio_data = audio_data.astype('<f4')
+
+        # Generate segments
+        segments = inferencer.generate_all_segments(
+            audio_data=audio_data,
+            task=Speech2TextTask.TRANSCRIBE,
+            language="en",
+            timeout_ms=15000
+        )
 
-        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
+        if not segments:
+            return ""
 
-        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        output = ''.join([seg.text for seg in segments]).strip()
+
+        # Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix common misspellings of BMO
+        # Fix capitalization of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
-    except subprocess.CalledProcessError as e:
-        logger.error(f"FFmpeg or Whisper process failed: {e}")
-        return ""
     except Exception as e:
-        logger.error(f"Transcription Error: {e}")
+        logger.error(f"Hailo Transcription Error: {e}")
         return ""
     finally:
-        # Clean up the temporary 16k wav file
         if os.path.exists(temp_wav):
             try:
                 os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
+            except Exception:
+                pass

commit 01017a0db759548f6f780aa6f3142784d36186cf
Author: Will Moore <will@clevercode.ca>
Date:   Fri Feb 27 16:03:02 2026 -0500

    Revert hallucinated hailo-whisper integration to use working whisper.cpp pipeline

diff --git a/core/stt.py b/core/stt.py
index f1c91e1..5b7027d 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -1,90 +1,56 @@
+import subprocess
 import logging
 import os
 import re
-import soundfile as sf
-import librosa
-import numpy as np
-from .config import WHISPER_MODEL
-
-try:
-    from hailo_whisper import HailoWhisper
-except ImportError:
-    HailoWhisper = None
-    print("WARNING: hailo-whisper is not installed. STT will fail.")
+from .config import WHISPER_CMD, WHISPER_MODEL
 
 logger = logging.getLogger(__name__)
 
-# Global inferencer to avoid reloading the HEF model for every sentence
-_inferencer = None
-
-def get_inferencer():
-    global _inferencer
-    if _inferencer is None:
-        if HailoWhisper is None:
-            logger.error("hailo-whisper library is missing!")
-            return None
-        
-        if not os.path.exists(WHISPER_MODEL):
-            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
-            logger.error("Please ensure Whisper-Base.hef is in the models directory.")
-            return None
-            
-        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
-        try:
-            _inferencer = HailoWhisper(WHISPER_MODEL)
-            logger.info("Hailo Whisper model loaded successfully on the NPU.")
-        except Exception as e:
-            logger.error(f"Failed to load Hailo Whisper model: {e}")
-            return None
-            
-    return _inferencer
-
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Transcribes the audio file using the Hailo-10H NPU via hailo-whisper.
+    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    inferencer = get_inferencer()
-    if inferencer is None:
-        return ""
+    temp_wav = f"{audio_filepath}_16k.wav"
 
     try:
-        logger.info(f"Loading and resampling {audio_filepath} to 16kHz for NPU inference...")
-        # Load and convert to 16kHz mono explicitly using librosa
-        audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
-        
-        # Write back to a clean 16k wav temp file since HailoWhisper transcribe() takes a file path
-        temp_wav = f"{audio_filepath}_16k.wav"
-        sf.write(temp_wav, audio_data, 16000)
-        
-        logger.info("Transcribing audio on the Hailo NPU...")
-        result = inferencer.transcribe(temp_wav)
-        
-        # Clean up temp file
-        if os.path.exists(temp_wav):
-            try:
-                os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
-            
-        # Parse the result
-        if isinstance(result, dict) and 'text' in result:
-            output = result['text'].strip()
-        else:
-            output = str(result).strip()
-
-        # Clean up tags or timestamp brackets that may leak
+        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
+        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
+        subprocess.run(
+            ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
+            check=True,
+            stdout=subprocess.DEVNULL,
+            stderr=subprocess.DEVNULL
+        )
+
+        # 2. Run whisper.cpp
+        logger.info("Running whisper.cpp transcription...")
+        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
+
+        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
+
+        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix capitalization of BMO
+        # Fix common misspellings of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
+    except subprocess.CalledProcessError as e:
+        logger.error(f"FFmpeg or Whisper process failed: {e}")
+        return ""
     except Exception as e:
-        logger.error(f"Hailo Transcription Error: {e}")
+        logger.error(f"Transcription Error: {e}")
         return ""
+    finally:
+        # Clean up the temporary 16k wav file
+        if os.path.exists(temp_wav):
+            try:
+                os.remove(temp_wav)
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")

commit 85808e3a909a91936f5602fe503915317788631f
Author: Will Moore <will@clevercode.ca>
Date:   Thu Feb 26 11:53:56 2026 -0800

    Add Whisper-Base.hef and update configs
    
    Replace references to whisper-small.hef with Whisper-Base.hef, add the Whisper-Base.hef model file, and update related messages and setup steps. Updated README to reference the included Whisper-Base.hef, changed WHISPER_MODEL paths in bmo/config.py and core/config.py, adjusted the core/stt.py error log to mention Whisper-Base.hef, and removed the manual-download warning from setup.sh so the repository now includes a tested Hailo HEF model.

diff --git a/core/stt.py b/core/stt.py
index 21ff916..f1c91e1 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -26,7 +26,7 @@ def get_inferencer():
         
         if not os.path.exists(WHISPER_MODEL):
             logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
-            logger.error("Please download whisper-small.hef (or base) and place it in the models directory.")
+            logger.error("Please ensure Whisper-Base.hef is in the models directory.")
             return None
             
         logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")

commit 97ed41ba805d271dcdba5cdeb51ead230195a1e2
Author: Will Moore <will@clevercode.ca>
Date:   Thu Feb 26 11:07:43 2026 -0800

    Integrate Hailo Whisper STT and config updates
    
    Switch STT pipeline to hailo-whisper (Hailo-10H NPU): add a hailo_whisper-based transcribe flow with librosa/soundfile preprocessing, a persistent inferencer loader, error handling and temp WAV cleanup. Update configs to point to models/whisper-small.hef and standardize LLM/Vision model names to llama3.2:1b / qwen2-vl-instruct:2b where applicable. Update README with Hailo Whisper usage, model download instructions, and models/ folder note. Modify setup.sh to create models/ and warn users to manually place the .hef file. Logging and user-facing warnings added when hailo-whisper or the HEF model are missing.

diff --git a/core/stt.py b/core/stt.py
index 5b7027d..21ff916 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -1,56 +1,90 @@
-import subprocess
 import logging
 import os
 import re
-from .config import WHISPER_CMD, WHISPER_MODEL
+import soundfile as sf
+import librosa
+import numpy as np
+from .config import WHISPER_MODEL
+
+try:
+    from hailo_whisper import HailoWhisper
+except ImportError:
+    HailoWhisper = None
+    print("WARNING: hailo-whisper is not installed. STT will fail.")
 
 logger = logging.getLogger(__name__)
 
+# Global inferencer to avoid reloading the HEF model for every sentence
+_inferencer = None
+
+def get_inferencer():
+    global _inferencer
+    if _inferencer is None:
+        if HailoWhisper is None:
+            logger.error("hailo-whisper library is missing!")
+            return None
+        
+        if not os.path.exists(WHISPER_MODEL):
+            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
+            logger.error("Please download whisper-small.hef (or base) and place it in the models directory.")
+            return None
+            
+        logger.info(f"Loading Hailo Whisper model from {WHISPER_MODEL}...")
+        try:
+            _inferencer = HailoWhisper(WHISPER_MODEL)
+            logger.info("Hailo Whisper model loaded successfully on the NPU.")
+        except Exception as e:
+            logger.error(f"Failed to load Hailo Whisper model: {e}")
+            return None
+            
+    return _inferencer
+
 def transcribe_audio(audio_filepath: str) -> str:
     """
-    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
+    Transcribes the audio file using the Hailo-10H NPU via hailo-whisper.
     """
     if not os.path.exists(audio_filepath):
         logger.error(f"Audio file not found: {audio_filepath}")
         return ""
 
-    temp_wav = f"{audio_filepath}_16k.wav"
+    inferencer = get_inferencer()
+    if inferencer is None:
+        return ""
 
     try:
-        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
-        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
-        subprocess.run(
-            ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
-            check=True,
-            stdout=subprocess.DEVNULL,
-            stderr=subprocess.DEVNULL
-        )
-
-        # 2. Run whisper.cpp
-        logger.info("Running whisper.cpp transcription...")
-        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
-
-        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
-
-        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        logger.info(f"Loading and resampling {audio_filepath} to 16kHz for NPU inference...")
+        # Load and convert to 16kHz mono explicitly using librosa
+        audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
+        
+        # Write back to a clean 16k wav temp file since HailoWhisper transcribe() takes a file path
+        temp_wav = f"{audio_filepath}_16k.wav"
+        sf.write(temp_wav, audio_data, 16000)
+        
+        logger.info("Transcribing audio on the Hailo NPU...")
+        result = inferencer.transcribe(temp_wav)
+        
+        # Clean up temp file
+        if os.path.exists(temp_wav):
+            try:
+                os.remove(temp_wav)
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
+            
+        # Parse the result
+        if isinstance(result, dict) and 'text' in result:
+            output = result['text'].strip()
+        else:
+            output = str(result).strip()
+
+        # Clean up tags or timestamp brackets that may leak
         output = re.sub(r'\[.*?\]', '', output).strip()
 
-        # Fix common misspellings of BMO
+        # Fix capitalization of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
         return output
 
-    except subprocess.CalledProcessError as e:
-        logger.error(f"FFmpeg or Whisper process failed: {e}")
-        return ""
     except Exception as e:
-        logger.error(f"Transcription Error: {e}")
+        logger.error(f"Hailo Transcription Error: {e}")
         return ""
-    finally:
-        # Clean up the temporary 16k wav file
-        if os.path.exists(temp_wav):
-            try:
-                os.remove(temp_wav)
-            except Exception as e:
-                logger.warning(f"Could not remove temp file {temp_wav}: {e}")

commit 852c78a36db6373b298497ab166d71674a0c0da4
Author: Will Moore <will@clevercode.ca>
Date:   Wed Feb 25 07:20:40 2026 -0800

    Fix STT module to return transcribed text

diff --git a/core/stt.py b/core/stt.py
index 75055e0..5b7027d 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -15,7 +15,7 @@ def transcribe_audio(audio_filepath: str) -> str:
         return ""
 
     temp_wav = f"{audio_filepath}_16k.wav"
-    
+
     try:
         # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
         logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
@@ -29,16 +29,18 @@ def transcribe_audio(audio_filepath: str) -> str:
         # 2. Run whisper.cpp
         logger.info("Running whisper.cpp transcription...")
         cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
-        
+
         output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
-        
+
         # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
         output = re.sub(r'\[.*?\]', '', output).strip()
-        
+
         # Fix common misspellings of BMO
         output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
         output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
+        return output
+
     except subprocess.CalledProcessError as e:
         logger.error(f"FFmpeg or Whisper process failed: {e}")
         return ""

commit 3674a5abe2e1afb70f9704d61302f6c942b94734
Author: Will Moore <will@clevercode.ca>
Date:   Tue Feb 24 21:46:26 2026 -0800

    Fix bemo transcription, update system prompt, and add script to generate more sounds

diff --git a/core/stt.py b/core/stt.py
index 1ee4da8..75055e0 100644
--- a/core/stt.py
+++ b/core/stt.py
@@ -35,7 +35,9 @@ def transcribe_audio(audio_filepath: str) -> str:
         # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
         output = re.sub(r'\[.*?\]', '', output).strip()
         
-        return output
+        # Fix common misspellings of BMO
+        output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
+        output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
 
     except subprocess.CalledProcessError as e:
         logger.error(f"FFmpeg or Whisper process failed: {e}")

commit 362f0914b21f9fc19a95a4db127a173f41836b9e
Author: Will Moore <will@clevercode.ca>
Date:   Mon Feb 23 15:40:34 2026 -0800

    Add browser mic and whisper-based STT
    
    Introduce a unified speech-to-text flow using whisper.cpp and browser recording. Added core/stt.py (transcribe_audio) and WHISPER_CMD/WHISPER_MODEL config entries; replaced inline whisper logic in agent_hailo.py to call the new module. Exposed a /api/transcribe endpoint in web_app.py to receive uploaded audio, save temporarily, call transcribe_audio, return the transcribed text, and clean up temp files. Updated templates/index.html to add a microphone button, UI/CSS, and client-side MediaRecorder logic to record, upload, and auto-send transcribed text. Added python-multipart to requirements. Binary wakeword.onnx was also updated.

diff --git a/core/stt.py b/core/stt.py
new file mode 100644
index 0000000..1ee4da8
--- /dev/null
+++ b/core/stt.py
@@ -0,0 +1,52 @@
+import subprocess
+import logging
+import os
+import re
+from .config import WHISPER_CMD, WHISPER_MODEL
+
+logger = logging.getLogger(__name__)
+
+def transcribe_audio(audio_filepath: str) -> str:
+    """
+    Converts any audio file to 16kHz WAV and runs whisper.cpp to transcribe it.
+    """
+    if not os.path.exists(audio_filepath):
+        logger.error(f"Audio file not found: {audio_filepath}")
+        return ""
+
+    temp_wav = f"{audio_filepath}_16k.wav"
+    
+    try:
+        # 1. Convert audio to 16kHz mono WAV (required by whisper.cpp)
+        logger.info(f"Converting {audio_filepath} to 16kHz WAV...")
+        subprocess.run(
+            ["ffmpeg", "-y", "-i", audio_filepath, "-ar", "16000", "-ac", "1", temp_wav],
+            check=True,
+            stdout=subprocess.DEVNULL,
+            stderr=subprocess.DEVNULL
+        )
+
+        # 2. Run whisper.cpp
+        logger.info("Running whisper.cpp transcription...")
+        cmd = [WHISPER_CMD, "-m", WHISPER_MODEL, "-f", temp_wav, "-nt"]
+        
+        output = subprocess.check_output(cmd, stderr=subprocess.DEVNULL).decode("utf-8").strip()
+        
+        # 3. Clean up output (remove timestamps like [00:00:00.000 --> 00:00:02.000] or [BLANK_AUDIO])
+        output = re.sub(r'\[.*?\]', '', output).strip()
+        
+        return output
+
+    except subprocess.CalledProcessError as e:
+        logger.error(f"FFmpeg or Whisper process failed: {e}")
+        return ""
+    except Exception as e:
+        logger.error(f"Transcription Error: {e}")
+        return ""
+    finally:
+        # Clean up the temporary 16k wav file
+        if os.path.exists(temp_wav):
+            try:
+                os.remove(temp_wav)
+            except Exception as e:
+                logger.warning(f"Could not remove temp file {temp_wav}: {e}")
