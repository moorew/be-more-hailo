import logging
import os
import sys
import re
import librosa
import numpy as np

# Make sure hailo_platform genai can be found
sys.path.append("/usr/lib/python3/dist-packages")

from .config import WHISPER_MODEL

try:
    from hailo_platform import VDevice
    from hailo_platform.genai import Speech2Text, Speech2TextTask
    _HAILO_AVAILABLE = True
except ImportError as e:
    _HAILO_AVAILABLE = False
    print(f"WARNING: hailo_platform is not installed or accessible. STT will fail. {e}")

logger = logging.getLogger(__name__)

# Multiplexed NPU group
_SHARED_VDEVICE_GROUP_ID = "SHARED"

_vdevice = None
_speech2text = None

def get_inferencer():
    global _vdevice, _speech2text
    
    if not _HAILO_AVAILABLE:
        logger.error("hailo_platform library is missing! Cannot run STT.")
        return None

    if _speech2text is None:
        if not os.path.exists(WHISPER_MODEL):
            logger.error(f"Whisper HEF model not found at: {WHISPER_MODEL}")
            return None
            
        logger.info("Initializing Hailo VDevice for STT...")
        try:
            params = VDevice.create_params()
            params.group_id = _SHARED_VDEVICE_GROUP_ID
            _vdevice = VDevice(params)
            
            abs_model_path = os.path.abspath(WHISPER_MODEL)
            logger.info(f"Loading Hailo Whisper model from {abs_model_path}...")
            _speech2text = Speech2Text(_vdevice, abs_model_path)
            logger.info("Native Hailo Whisper model loaded successfully on the NPU.")
        except Exception as e:
            logger.error(f"Failed to load Native Hailo Whisper model: {e}", exc_info=True)
            return None
            
    return _speech2text

def transcribe_audio(audio_filepath: str) -> str:
    """
    Transcribes the audio file using the Hailo-10H NPU via Native GenAI API.
    """
    if not os.path.exists(audio_filepath):
        logger.error(f"Audio file not found: {audio_filepath}")
        return ""

    speech2text = get_inferencer()
    if speech2text is None:
        return ""

    try:
        logger.info(f"Loading {audio_filepath} and resampling to 16kHz mono for NPU inference...")
        
        # Load audio using librosa (forces 16kHz mono explicitly)
        audio_data, _ = librosa.load(audio_filepath, sr=16000, mono=True)
        
        # Convert to float32 as expected by C++ GenAI wrapper and ensure little-endian
        audio_data = audio_data.astype(np.float32)
        audio_data = audio_data.astype('<f4')
        
        logger.info("Transcribing audio with Native Whisper NPU...")
        segments = speech2text.generate_all_segments(
            audio_data=audio_data,
            task=Speech2TextTask.TRANSCRIBE,
            language="en",
            timeout_ms=15000
        )
        
        if segments and len(segments) > 0:
            transcription = ''.join([seg.text for seg in segments])
            logger.info(f"Transcription completed: {transcription.strip()}")
            output = transcription.strip()
            
            # Clean up tags or timestamp brackets that may leak
            output = re.sub(r'\[.*?\]', '', output).strip()

            # Fix capitalization of BMO
            output = re.sub(r'\b[Bb]emo\b', 'BMO', output)
            output = re.sub(r'\b[Bb]eemo\b', 'BMO', output)
            
            # Clean hallucinated whispers from silence
            lowered = output.lower()
            if lowered in ["[silence]", "(silence)", "you", "thanks for watching!", "[blank_audio]"]:
                return ""
            
            return output
        else:
            logger.warning("No transcription generated by Hailo NPU.")
            return ""
            
    except Exception as e:
        logger.error(f"Hailo Transcription Error: {e}", exc_info=True)
        return ""
